{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Locally\n",
    "\n",
    "This is a simple notebook to run a local experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmodel.core import orchestrator\n",
    "\n",
    "environment_config_path = \"~/.product-search.env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 19:48:39,942 name=ffmodel.core.orchestrator level=INFO Starting local experiment with solution-id - 04 and run-id willing_train_jx3dstvj2p \n",
      "2023-10-12 19:48:39,943 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-12 19:48:39,944 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-12 19:48:39,944 name=ffmodel.core.orchestrator level=METRICS solution_config \n",
      "2023-10-12 19:48:39,945 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.static_context_from_file to the pipeline. \n",
      "2023-10-12 19:48:39,952 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.few_shots_from_file to the pipeline. \n",
      "2023-10-12 19:48:39,955 name=ffmodel.core.orchestrator level=INFO Adding component components.stitchers.openai_chat_completions to the pipeline. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local environment configs from file.\n",
      "Loaded 2 configs from file '/Users/jorgeluna/.product-search.env'.\n",
      "Key vault url not set. Skipping key vault client initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 19:48:40,325 name=ffmodel.core.orchestrator level=INFO Adding component components.model_callers.openai_chat_completions to the pipeline. \n",
      "2023-10-12 19:48:40,343 name=ffmodel.core.orchestrator level=INFO Adding component components.post_processors.minify_json to the pipeline. \n",
      "2023-10-12 19:48:40,351 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.json_schema to the pipeline. \n",
      "/Users/jorgeluna/work/ffmodel-projects/ffmodel/lib/python3.11/site-packages/thefuzz/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "2023-10-12 19:48:40,361 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.fuzzy to the pipeline. \n",
      "[nltk_data] Downloading package punkt to /Users/jorgeluna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2023-10-12 19:48:41,860 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.bleu to the pipeline. \n",
      "2023-10-12 19:48:41,878 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.rouge to the pipeline. \n",
      "2023-10-12 19:48:41,878 name=ffmodel.core.orchestrator level=INFO Beginning execution... \n",
      "2023-10-12 19:48:41,879 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.static_context_from_file' \n",
      "2023-10-12 19:48:41,879 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.few_shots_from_file' \n",
      "2023-10-12 19:48:41,879 name=ffmodel.core.orchestrator level=INFO Executing 'components.stitchers.openai_chat_completions' \n",
      "2023-10-12 19:48:41,880 name=ffmodel.core.orchestrator level=INFO Executing 'components.model_callers.openai_chat_completions' \n",
      "2023-10-12 19:48:54,987 name=ffmodel.core.orchestrator level=INFO Executing 'components.post_processors.minify_json' \n",
      "2023-10-12 19:48:54,987 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.json_schema' \n",
      "2023-10-12 19:48:55,001 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.fuzzy' \n",
      "2023-10-12 19:48:55,062 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.bleu' \n",
      "2023-10-12 19:49:05,361 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.rouge' \n",
      "2023-10-12 19:49:05,362 name=ffmodel.core.orchestrator level=INFO Finished execution\n",
      "Returning data models \n",
      "2023-10-12 19:49:05,513 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-12 19:49:05,521 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-12 19:49:05,552 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-12 19:49:05,552 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-12 19:49:05,556 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-12 19:49:05,571 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-12 19:49:05,571 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-12 19:49:05,581 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-12 19:49:05,617 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-12 19:49:05,617 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-12 19:49:05,621 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-12 19:49:05,636 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-12 19:49:05,636 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-12 19:49:05,646 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-12 19:49:05,682 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-12 19:49:05,683 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-12 19:49:05,687 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-12 19:49:05,706 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-12 19:49:05,706 name=ffmodel.core.orchestrator level=INFO Finished local experiment \n"
     ]
    }
   ],
   "source": [
    "solution_config_path = \"./configs/01_baseline.yaml\"\n",
    "#solution_config_path = \"./configs/02_with_fewshots_01 _min.yaml\"\n",
    "#solution_config_path = \"./configs/03_with_fewshots_01.yaml\"\n",
    "#solution_config_path = \"./configs/05_with_fewshots_02_min.yaml\"\n",
    "#solution_config_path = \"./configs/04_with_fewshots_02.yaml\"\n",
    "\n",
    "data_models = orchestrator.execute_experiment_on_local(solution_config_path, environment_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"component_data\": {},\n",
      "    \"context\": [\n",
      "        \"*You are bot that takes orders at a pizza and wings restaurant\\n*You take orders in natural language and translate it to a formatted json object\\n*Results should be provided in a structured output that is json format that adheres to this schema\\n    {\\\"$schema\\\":\\\"http://json-schema.org/draft-07/schema#\\\",\\\"type\\\":\\\"array\\\",\\\"description\\\":\\\"An array of items in the order\\\",\\\"items\\\":{\\\"type\\\":\\\"object\\\",\\\"oneOf\\\":[{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"specialty pizza\\\"},\\\"name\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of the pizza\\\"},\\\"size\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The size of the pizza\\\"},\\\"crust\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The type of crust for the pizza\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the pizza in the order\\\"}},\\\"required\\\":[\\\"type\\\",\\\"name\\\",\\\"quantity\\\",\\\"size\\\",\\\"crust\\\"]},{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"custom pizza\\\"},\\\"size\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The size of the pizza\\\"},\\\"crust\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The type of crust for the pizza\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the pizza in the order\\\"},\\\"toppings\\\":{\\\"type\\\":\\\"array\\\",\\\"description\\\":\\\"An array of toppings on the pizza\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of a topping\\\"}}},\\\"required\\\":[\\\"type\\\",\\\"size\\\",\\\"crust\\\",\\\"quantity\\\",\\\"toppings\\\"]},{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"wings\\\"},\\\"name\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of the wings\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the wings in the order\\\"},\\\"flavor\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The flavor of the wings\\\"}},\\\"required\\\":[\\\"type\\\",\\\"name\\\",\\\"quantity\\\",\\\"flavor\\\"]},{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"drink\\\"},\\\"name\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of the drink\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the drink in the order\\\"},\\\"size\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The size of the drink\\\"}},\\\"required\\\":[\\\"type\\\",\\\"name\\\",\\\"quantity\\\",\\\"size\\\"]},{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"topping\\\"},\\\"name\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of the topping\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the topping in the order\\\"}},\\\"required\\\":[\\\"type\\\",\\\"name\\\",\\\"quantity\\\"]}]}}\\n*If asked to order anything that is not related to pizza, wings, or drinks, you politely decline.\\n\"\n",
      "    ],\n",
      "    \"completion_pairs\": [\n",
      "        [\n",
      "            \"Two large pepperoni and mushroom pizzas and 1 medium veggie deluxe\",\n",
      "            \"{\\\"items\\\": [{\\\"type\\\": \\\"specialty pizza\\\", \\\"name\\\": \\\"Veggie Deluxe\\\", \\\"size\\\": \\\"medium\\\", \\\"crust\\\": \\\"regular\\\", \\\"quantity\\\": 1}, {\\\"type\\\": \\\"custom pizza\\\", \\\"size\\\": \\\"large\\\", \\\"crust\\\": \\\"regular\\\", \\\"quantity\\\": 2, \\\"toppings\\\": [\\\"pepperoni\\\", \\\"mushrooms\\\"]}]}\"\n",
      "        ],\n",
      "        [\n",
      "            \"10 piece garlic parmesan wings and 2 small sprites\",\n",
      "            \"{\\\"items\\\": [{\\\"type\\\": \\\"wings\\\", \\\"name\\\": \\\"Garlic Parmesan\\\", \\\"quantity\\\": 10, \\\"flavor\\\": \\\"mild\\\"}, {\\\"type\\\": \\\"drink\\\", \\\"name\\\": \\\"Sprite\\\", \\\"quantity\\\": 2, \\\"size\\\": \\\"small\\\"}]}\"\n",
      "        ],\n",
      "        [\n",
      "            \"One Hawaiian regular crust pizza and a medium thin crust with sausage, green olives, onions and jalapenos\",\n",
      "            \"{\\\"items\\\": [{\\\"type\\\": \\\"specialty pizza\\\", \\\"name\\\": \\\"Hawaiian\\\", \\\"size\\\": \\\"large\\\", \\\"crust\\\": \\\"hand-tossed\\\", \\\"quantity\\\": 1}, {\\\"type\\\": \\\"custom pizza\\\", \\\"size\\\": \\\"medium\\\", \\\"crust\\\": \\\"thin\\\", \\\"quantity\\\": 1, \\\"toppings\\\": [\\\"sausage\\\", \\\"green olives\\\", \\\"onions\\\", \\\"jalapenos\\\"]}]}\"\n",
      "        ],\n",
      "        [\n",
      "            \"50 extra hot buffalo wings and a 2 liter sprite\",\n",
      "            \"{\\\"items\\\": [{\\\"type\\\": \\\"wings\\\", \\\"name\\\": \\\"Buffalo\\\", \\\"quantity\\\": 50, \\\"flavor\\\": \\\"extra hot\\\"}, {\\\"type\\\": \\\"drink\\\", \\\"name\\\": \\\"Sprite\\\", \\\"quantity\\\": 1, \\\"size\\\": \\\"2 liter\\\"}]}\"\n",
      "        ],\n",
      "        [\n",
      "            \"Pizza for 3 with everything on it and a 3 of sprites\",\n",
      "            \"{\\\"items\\\": [{\\\"type\\\": \\\"drink\\\", \\\"name\\\": \\\"Fanta\\\", \\\"quantity\\\": 3, \\\"size\\\": \\\"medium\\\"}, {\\\"type\\\": \\\"specialty pizza\\\", \\\"name\\\": \\\"Supreme\\\", \\\"size\\\": \\\"medium\\\", \\\"crust\\\": \\\"thin\\\", \\\"quantity\\\": 1}]}\"\n",
      "        ]\n",
      "    ],\n",
      "    \"session\": [],\n",
      "    \"user_nl\": \"Two large pepperoni and mushroom pizzas with thick crust and 1 medium thin crust veggie deluxe\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(data_models[i].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"items\": [{\"type\": \"specialty pizza\", \"name\": \"Veggie Deluxe\", \"size\": \"medium\", \"crust\": \"thin\", \"quantity\": 1}, {\"type\": \"custom pizza\", \"size\": \"large\", \"crust\": \"thick\", \"quantity\": 2, \"toppings\": [\"pepperoni\", \"mushrooms\"]}]}']\n"
     ]
    }
   ],
   "source": [
    "print(data_models[i].model_output.completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'items': [{'type': 'specialty pizza', 'name': 'Veggie Deluxe', 'size': 'medium', 'crust': 'thin', 'quantity': 1}, {'type': 'custom pizza', 'size': 'large', 'crust': 'pan', 'quantity': 2, 'toppings': ['pepperoni', 'mushrooms']}]}]\n"
     ]
    }
   ],
   "source": [
    "print(data_models[i].request.expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'components.model_callers.openai_chat_completions': {'completion_tokens': [82],\n",
       "  'prompt_tokens': [1160],\n",
       "  'total_tokens': [1242]},\n",
       " 'components.evaluators.json_schema': {'valid_syntax': [1],\n",
       "  'valid_object': [0]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_models[i].experiment_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lseg-cond-sum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
