# Fine-Tuning Recommendations

## When to consider fine-tuning

In some cases, LLMs may not perform well on specific domains, tasks, or datasets, or may produce inaccurate or misleading outputs. In such cases, fine-tuning the model can be a useful technique to adapt it to the desired goal and improve its quality and reliability. Below are some scenarios where fine-tuning can be considered.

- **When the model is making untrue statements (“hallucinations”)** – hallucinations which can harm the credibility and trustworthiness of the model and its outputs. One possible mitigation is by fine-tuning the model with data that contains accurate and consistent information.
- **When the accuracy of the model does not meet customer requirements** – sometimes the pre-trained model may not achieve the desired level of accuracy or quality for a specific task or domain. This can be due to the mismatch between the pre-training data and the target data, the diversity and complexity of the target data, or the evaluation metrics and criteria. Fine-tuning the model with data that is representative and relevant to the target task or domain may help improve the model's performance.
- **When teaching the model new (uncommon) tasks or constraining it to a smaller space, especially complex specialized tasks** – some tasks or domains may require the model to learn new skills, concepts, or vocabulary that are not well captured by the pre-training data, such as legal, medical, or technical texts. These tasks or domains may also have specific constraints or requirements, such as length, format, or style, that limit the model's generative space. Fine-tuning the model with domain-specific data may help the model acquire the necessary knowledge and skills and generate more appropriate and coherent texts.
- **When using more data than you can fit in the prompt** – the prompt is the input text that is given to the model to generate an output, and it usually contains some keywords, instructions, or examples that guide the model's behavior. However, the prompt has a limited size, and sometimes the data that is needed to complete the task or domain may exceed the prompt's capacity, such as long documents, tables, etc. In such cases, fine-tuning can help the model handle more data and use smaller prompts at inference time to generate more relevant and complete outputs.
- **When there is a need to make prompt engineering simpler, use less tokens and/or improve latency** – building complex prompts (using prompt engineering) may affect the model's efficiency and scalability. Fine-tuning the model with data that is tailored to the target task or domain, can help the model learn from simpler prompts, and hence, use less tokens, and improve latency.
  
## Best practices for fine-tuning

Similar to prompt engineering, there are some best practices that can help improve the efficiency and effectiveness of fine-tuning LLMs for various applications. Here are some of them:

- Try different data formats, but ensure they are suitable for your application. Depending on the task, different data formats can have different impacts on the model’s performance. For example, for a classification task, you can use a format that separates the prompt and the completion with a special token, such as {"prompt": “Paris##\n", "completion": “ city\n###\n"}.
- Collect a large high-quality dataset. LLMs are data-hungry and can benefit from having more diverse and representative data to fine-tune on. However, collecting and annotating large datasets can be costly and time-consuming. Therefore, you can also leverage synthetic data generation techniques to increase the size and variety of your dataset. However, you should also ensure that the synthetic data is relevant and consistent with your task and domain and does not introduce noise or bias to the model.
- To assess the value of getting more data, you can fine-tune models on subsets of your current dataset (e.g., 25%, 50%, 100%) to see how performance scales with dataset size. This can help you estimate the learning curve of your model and decide whether adding more data is worth the effort and cost. You can also compare the performance of your model with the pre-trained model or a baseline model to see how much improvement you can achieve with fine-tuning.
- Iteratively adjust hyper-parameters to optimize the model performance. Hyper-parameters, such as the learning rate, the batch size and the number of epochs can have a significant impact on the model’s performance. Therefore, you should experiment with different values and combinations of hyper-parameters to find the best ones for your task and dataset.
- Start with a smaller model, especially for simpler tasks, then try larger models if needed.
