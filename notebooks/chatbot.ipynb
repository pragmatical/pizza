{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A pizza order bot\n",
    "\n",
    "This sample notebook demonstrates  creation of a simple chatbot that uses an FFModel inference endpoint which in turn calls OpenAPI chat completions api.   The goal is to demonstrate interactions with the endpoint in a scenario that requires history being sent with the prompt.  The endpoint is designed to return json so successful results will look \"funny\" in the chat.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmodel.core.inference_endpoint import InferenceEndpoint\n",
    "\n",
    "environment_config_path = \"~/.chatbot.env\"\n",
    "\n",
    "#solution_config_path = \"../solution/configs/00_baseline.yaml\"\n",
    "#solution_config_path = \"../solution/configs/01_with_static_context_01.yaml\"\n",
    "#solution_config_path = \"../solution/configs/02_with_fewshots_01 _min.yaml\"\n",
    "#solution_config_path = \"../solution/configs/03_with_fewshots_01.yaml\"\n",
    "solution_config_path = \"../solution/configs/05_with_fewshots_02_min.yaml\"\n",
    "#solution_config_path = \"../solution/configs/04_with_fewshots_02.yaml\"\n",
    "\n",
    "endpoint = InferenceEndpoint(solution_config_path, environment_config_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Define Request to OpenAI API\n",
    "For these labs we are using the Azure OpenAI Chat Completion API, this is different than the Completions API.  Information about its usage can be found here:\n",
    "<https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#chat-completions>\n",
    "The chat completions API takes a collection of messages to provide history and context of chat to the model.  This function takes a chat request object that ffmodel inference endpoint can use to create a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(chat_request):\n",
    "    response = endpoint.execute(chat_request)\n",
    "    return response.model_output.completions[0]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 The conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import typing\n",
    "import uuid\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from fastapi.encoders import jsonable_encoder\n",
    "\n",
    "class CompletionPair(BaseModel):\n",
    "    user_nl:str\n",
    "    completion:object\n",
    "\n",
    "class UserSession(BaseModel):\n",
    "    session_id:str\n",
    "    prior_responses:list[CompletionPair]\n",
    "    sequence: typing.Optional[int]\n",
    "\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    user_nl:str\n",
    "    session:UserSession\n",
    "\n",
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "max_response_tokens = 500\n",
    "token_limit=2048\n",
    "name = input('Enter Your Name: ')\n",
    "print ('Welcome to pizzaai.  What can I get for you?')\n",
    "conversation=[]\n",
    "session_id=str(uuid.uuid4())\n",
    "message_count=0\n",
    "while True:\n",
    "    request = input(name+':')\n",
    "    current_message={request}\n",
    "    chat_request=ChatRequest(user_nl=request,session=UserSession(session_id=session_id,sequence=message_count,prior_responses=conversation))\n",
    "    if request==\"Bye\" or request=='bye':\n",
    "        print('Bot: Bye')\n",
    "        break\n",
    "    else:\n",
    "        payload=json.dumps(jsonable_encoder(chat_request))\n",
    "        response = send_message(payload)\n",
    "        interaction = CompletionPair(user_nl=request,completion=response)\n",
    "        conversation.append(interaction)\n",
    "        message_count+=1\n",
    "        print('Bot: ', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc180f703c9255d3d630e6d09ed4eb3355d27845db546035ce1b410f2bfa43b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
