{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Locally\n",
    "\n",
    "This is a simple notebook to run a local experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmodel.core import orchestrator\n",
    "\n",
    "environment_config_path = \"~/.ffmodel.env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:04:58,292 name=ffmodel.core.orchestrator level=INFO Starting local experiment with solution-id - 03 and run-id strong_shoe_pqq460ncls \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:04:58,343 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:04:58,344 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:04:58,344 name=ffmodel.core.orchestrator level=METRICS solution_config \n",
      "2023-10-16 16:04:58,375 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.static_context_from_file to the pipeline. \n",
      "2023-10-16 16:04:58,389 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.few_shots_from_file to the pipeline. \n",
      "2023-10-16 16:04:58,399 name=ffmodel.core.orchestrator level=INFO Adding component components.stitchers.openai_chat_completions to the pipeline. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local environment configs from file.\n",
      "Loaded 2 configs from file '/Users/jorgeluna/.ffmodel.env'.\n",
      "Key vault url not set. Skipping key vault client initialization.\n",
      "FFModelLogger: Logging will print to console as no AppInsight connection was provided (config `ApplicationInsightConnectionString)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:04:59,193 name=ffmodel.core.orchestrator level=INFO Adding component components.model_callers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:04:59,198 name=ffmodel.core.orchestrator level=INFO Adding component components.post_processors.minify_json to the pipeline. \n",
      "2023-10-16 16:04:59,204 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.json_schema to the pipeline. \n",
      "2023-10-16 16:04:59,320 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.fuzzy to the pipeline. \n",
      "[nltk_data] Downloading package punkt to /Users/jorgeluna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2023-10-16 16:05:03,295 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.bleu to the pipeline. \n",
      "2023-10-16 16:05:03,429 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.rouge to the pipeline. \n",
      "2023-10-16 16:05:03,429 name=ffmodel.core.orchestrator level=INFO Beginning execution... \n",
      "2023-10-16 16:05:03,430 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.static_context_from_file' \n",
      "2023-10-16 16:05:03,430 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.few_shots_from_file' \n",
      "2023-10-16 16:05:03,430 name=ffmodel.core.orchestrator level=INFO Executing 'components.stitchers.openai_chat_completions' \n",
      "2023-10-16 16:05:03,431 name=ffmodel.core.orchestrator level=INFO Executing 'components.model_callers.openai_chat_completions' \n",
      "2023-10-16 16:05:10,402 name=ffmodel.core.orchestrator level=INFO Executing 'components.post_processors.minify_json' \n",
      "2023-10-16 16:05:10,404 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.json_schema' \n",
      "2023-10-16 16:05:10,411 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.fuzzy' \n",
      "2023-10-16 16:05:10,414 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.bleu' \n",
      "2023-10-16 16:05:24,137 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.rouge' \n",
      "2023-10-16 16:05:24,138 name=ffmodel.core.orchestrator level=INFO Finished execution\n",
      "Returning data models \n",
      "2023-10-16 16:05:24,328 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:24,338 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:24,375 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:24,375 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:24,380 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:24,399 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:24,399 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:24,412 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:24,457 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:24,458 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:24,463 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:24,482 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:24,483 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:24,495 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:24,541 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:24,541 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:24,547 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:24,570 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:24,570 name=ffmodel.core.orchestrator level=INFO Finished local experiment \n",
      "2023-10-16 16:05:24,587 name=ffmodel.core.orchestrator level=INFO Starting local experiment with solution-id - 00 and run-id serene_toe_jn2yccdvxj \n",
      "2023-10-16 16:05:24,588 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:05:24,589 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:05:24,589 name=ffmodel.core.orchestrator level=METRICS solution_config \n",
      "2023-10-16 16:05:24,590 name=ffmodel.core.orchestrator level=INFO Adding component components.stitchers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:05:24,590 name=ffmodel.core.orchestrator level=INFO Adding component components.model_callers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:05:24,594 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.json_schema to the pipeline. \n",
      "2023-10-16 16:05:24,595 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.fuzzy to the pipeline. \n",
      "2023-10-16 16:05:24,596 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.bleu to the pipeline. \n",
      "2023-10-16 16:05:24,596 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.rouge to the pipeline. \n",
      "2023-10-16 16:05:24,596 name=ffmodel.core.orchestrator level=INFO Beginning execution... \n",
      "2023-10-16 16:05:24,597 name=ffmodel.core.orchestrator level=INFO Executing 'components.stitchers.openai_chat_completions' \n",
      "2023-10-16 16:05:24,597 name=ffmodel.core.orchestrator level=INFO Executing 'components.model_callers.openai_chat_completions' \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local environment configs from file.\n",
      "Loaded 2 configs from file '/Users/jorgeluna/.ffmodel.env'.\n",
      "Key vault url not set. Skipping key vault client initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:05:27,491 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.json_schema' \n",
      "2023-10-16 16:05:27,492 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.fuzzy' \n",
      "2023-10-16 16:05:27,493 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.bleu' \n",
      "2023-10-16 16:05:32,847 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.rouge' \n",
      "2023-10-16 16:05:32,848 name=ffmodel.core.orchestrator level=INFO Finished execution\n",
      "Returning data models \n",
      "2023-10-16 16:05:32,925 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:32,926 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:32,931 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:32,931 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:32,935 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:32,951 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:32,952 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:32,957 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:32,977 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:32,978 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:32,983 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:33,005 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:33,008 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:33,010 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:33,017 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:33,018 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:33,021 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:33,038 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:33,039 name=ffmodel.core.orchestrator level=INFO Finished local experiment \n",
      "2023-10-16 16:05:33,048 name=ffmodel.core.orchestrator level=INFO Starting local experiment with solution-id - 04 and run-id sleepy_soccer_w7xl31l6x2 \n",
      "2023-10-16 16:05:33,049 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:05:33,049 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:05:33,049 name=ffmodel.core.orchestrator level=METRICS solution_config \n",
      "2023-10-16 16:05:33,051 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.static_context_from_file to the pipeline. \n",
      "2023-10-16 16:05:33,056 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.few_shots_from_file to the pipeline. \n",
      "2023-10-16 16:05:33,057 name=ffmodel.core.orchestrator level=INFO Adding component components.stitchers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:05:33,057 name=ffmodel.core.orchestrator level=INFO Adding component components.model_callers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:05:33,057 name=ffmodel.core.orchestrator level=INFO Adding component components.post_processors.minify_json to the pipeline. \n",
      "2023-10-16 16:05:33,058 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.json_schema to the pipeline. \n",
      "2023-10-16 16:05:33,058 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.fuzzy to the pipeline. \n",
      "2023-10-16 16:05:33,058 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.bleu to the pipeline. \n",
      "2023-10-16 16:05:33,059 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.rouge to the pipeline. \n",
      "2023-10-16 16:05:33,059 name=ffmodel.core.orchestrator level=INFO Beginning execution... \n",
      "2023-10-16 16:05:33,059 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.static_context_from_file' \n",
      "2023-10-16 16:05:33,060 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.few_shots_from_file' \n",
      "2023-10-16 16:05:33,060 name=ffmodel.core.orchestrator level=INFO Executing 'components.stitchers.openai_chat_completions' \n",
      "2023-10-16 16:05:33,061 name=ffmodel.core.orchestrator level=INFO Executing 'components.model_callers.openai_chat_completions' \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local environment configs from file.\n",
      "Loaded 2 configs from file '/Users/jorgeluna/.ffmodel.env'.\n",
      "Key vault url not set. Skipping key vault client initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:05:39,445 name=ffmodel.core.orchestrator level=INFO Executing 'components.post_processors.minify_json' \n",
      "2023-10-16 16:05:39,446 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.json_schema' \n",
      "2023-10-16 16:05:39,463 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.fuzzy' \n",
      "2023-10-16 16:05:39,464 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.bleu' \n",
      "2023-10-16 16:05:53,293 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.rouge' \n",
      "2023-10-16 16:05:53,294 name=ffmodel.core.orchestrator level=INFO Finished execution\n",
      "Returning data models \n",
      "2023-10-16 16:05:53,487 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:53,507 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:53,545 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:53,545 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:53,550 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:53,568 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:53,569 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:53,581 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:53,631 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:53,631 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:53,636 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:53,656 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:53,657 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:53,669 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:53,716 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:53,717 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:05:53,724 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:05:53,748 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:05:53,749 name=ffmodel.core.orchestrator level=INFO Finished local experiment \n",
      "2023-10-16 16:05:53,757 name=ffmodel.core.orchestrator level=INFO Starting local experiment with solution-id - 02 and run-id ashy_band_674zwh4yv0 \n",
      "2023-10-16 16:05:53,759 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:05:53,760 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:05:53,760 name=ffmodel.core.orchestrator level=METRICS solution_config \n",
      "2023-10-16 16:05:53,761 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.static_context_from_file to the pipeline. \n",
      "2023-10-16 16:05:53,767 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.few_shots_from_file to the pipeline. \n",
      "2023-10-16 16:05:53,768 name=ffmodel.core.orchestrator level=INFO Adding component components.stitchers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:05:53,768 name=ffmodel.core.orchestrator level=INFO Adding component components.model_callers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:05:53,768 name=ffmodel.core.orchestrator level=INFO Adding component components.post_processors.minify_json to the pipeline. \n",
      "2023-10-16 16:05:53,769 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.json_schema to the pipeline. \n",
      "2023-10-16 16:05:53,769 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.fuzzy to the pipeline. \n",
      "2023-10-16 16:05:53,770 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.bleu to the pipeline. \n",
      "2023-10-16 16:05:53,770 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.rouge to the pipeline. \n",
      "2023-10-16 16:05:53,770 name=ffmodel.core.orchestrator level=INFO Beginning execution... \n",
      "2023-10-16 16:05:53,771 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.static_context_from_file' \n",
      "2023-10-16 16:05:53,771 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.few_shots_from_file' \n",
      "2023-10-16 16:05:53,772 name=ffmodel.core.orchestrator level=INFO Executing 'components.stitchers.openai_chat_completions' \n",
      "2023-10-16 16:05:53,772 name=ffmodel.core.orchestrator level=INFO Executing 'components.model_callers.openai_chat_completions' \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local environment configs from file.\n",
      "Loaded 2 configs from file '/Users/jorgeluna/.ffmodel.env'.\n",
      "Key vault url not set. Skipping key vault client initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:06:00,992 name=ffmodel.core.orchestrator level=INFO Executing 'components.post_processors.minify_json' \n",
      "2023-10-16 16:06:00,993 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.json_schema' \n",
      "2023-10-16 16:06:01,006 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.fuzzy' \n",
      "2023-10-16 16:06:01,007 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.bleu' \n",
      "2023-10-16 16:06:14,347 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.rouge' \n",
      "2023-10-16 16:06:14,347 name=ffmodel.core.orchestrator level=INFO Finished execution\n",
      "Returning data models \n",
      "2023-10-16 16:06:14,535 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:14,545 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:14,582 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:14,582 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:14,587 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:14,605 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:14,606 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:14,618 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:14,664 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:14,664 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:14,669 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:14,688 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:14,689 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:14,701 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:14,746 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:14,746 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:14,752 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:14,775 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:14,776 name=ffmodel.core.orchestrator level=INFO Finished local experiment \n",
      "2023-10-16 16:06:14,788 name=ffmodel.core.orchestrator level=INFO Starting local experiment with solution-id - 07 and run-id purple_dog_c1qd0451ld \n",
      "2023-10-16 16:06:14,789 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:06:14,790 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:06:14,790 name=ffmodel.core.orchestrator level=METRICS solution_config \n",
      "2023-10-16 16:06:14,797 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.static_context_from_file to the pipeline. \n",
      "2023-10-16 16:06:14,798 name=ffmodel.core.orchestrator level=INFO Adding component components.stitchers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:06:14,798 name=ffmodel.core.orchestrator level=INFO Adding component components.model_callers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:06:14,799 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.json_schema to the pipeline. \n",
      "2023-10-16 16:06:14,799 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.fuzzy to the pipeline. \n",
      "2023-10-16 16:06:14,799 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.bleu to the pipeline. \n",
      "2023-10-16 16:06:14,800 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.rouge to the pipeline. \n",
      "2023-10-16 16:06:14,800 name=ffmodel.core.orchestrator level=INFO Beginning execution... \n",
      "2023-10-16 16:06:14,800 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.static_context_from_file' \n",
      "2023-10-16 16:06:14,800 name=ffmodel.core.orchestrator level=INFO Executing 'components.stitchers.openai_chat_completions' \n",
      "2023-10-16 16:06:14,801 name=ffmodel.core.orchestrator level=INFO Executing 'components.model_callers.openai_chat_completions' \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local environment configs from file.\n",
      "Loaded 2 configs from file '/Users/jorgeluna/.ffmodel.env'.\n",
      "Key vault url not set. Skipping key vault client initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:06:16,888 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.json_schema' \n",
      "2023-10-16 16:06:16,889 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.fuzzy' \n",
      "2023-10-16 16:06:16,890 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.bleu' \n",
      "2023-10-16 16:06:21,506 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.rouge' \n",
      "2023-10-16 16:06:21,507 name=ffmodel.core.orchestrator level=INFO Finished execution\n",
      "Returning data models \n",
      "2023-10-16 16:06:21,577 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:21,581 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:21,593 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:21,594 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:21,596 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:21,602 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:21,603 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:21,606 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:21,620 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:21,622 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:21,630 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:21,643 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:21,644 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:21,648 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:21,662 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:21,662 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:21,667 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:21,687 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:21,688 name=ffmodel.core.orchestrator level=INFO Finished local experiment \n",
      "2023-10-16 16:06:21,776 name=ffmodel.core.orchestrator level=INFO Starting local experiment with solution-id - 06 and run-id kind_drop_3xjb99zmph \n",
      "2023-10-16 16:06:21,777 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:06:21,777 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:06:21,778 name=ffmodel.core.orchestrator level=METRICS solution_config \n",
      "2023-10-16 16:06:21,778 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.static_context_from_file to the pipeline. \n",
      "2023-10-16 16:06:21,778 name=ffmodel.core.orchestrator level=INFO Adding component components.stitchers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:06:21,779 name=ffmodel.core.orchestrator level=INFO Adding component components.model_callers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:06:21,779 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.json_schema to the pipeline. \n",
      "2023-10-16 16:06:21,780 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.fuzzy to the pipeline. \n",
      "2023-10-16 16:06:21,780 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.bleu to the pipeline. \n",
      "2023-10-16 16:06:21,780 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.rouge to the pipeline. \n",
      "2023-10-16 16:06:21,780 name=ffmodel.core.orchestrator level=INFO Beginning execution... \n",
      "2023-10-16 16:06:21,780 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.static_context_from_file' \n",
      "2023-10-16 16:06:21,781 name=ffmodel.core.orchestrator level=INFO Executing 'components.stitchers.openai_chat_completions' \n",
      "2023-10-16 16:06:21,781 name=ffmodel.core.orchestrator level=INFO Executing 'components.model_callers.openai_chat_completions' \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local environment configs from file.\n",
      "Loaded 2 configs from file '/Users/jorgeluna/.ffmodel.env'.\n",
      "Key vault url not set. Skipping key vault client initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:06:23,915 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.json_schema' \n",
      "2023-10-16 16:06:23,915 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.fuzzy' \n",
      "2023-10-16 16:06:23,916 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.bleu' \n",
      "2023-10-16 16:06:28,581 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.rouge' \n",
      "2023-10-16 16:06:28,582 name=ffmodel.core.orchestrator level=INFO Finished execution\n",
      "Returning data models \n",
      "2023-10-16 16:06:28,648 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:28,651 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:28,663 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:28,663 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:28,665 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:28,672 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:28,672 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:28,676 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:28,688 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:28,689 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:28,691 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:28,699 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:28,699 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:28,703 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:28,717 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:28,717 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:28,722 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:28,744 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:28,745 name=ffmodel.core.orchestrator level=INFO Finished local experiment \n",
      "2023-10-16 16:06:28,768 name=ffmodel.core.orchestrator level=INFO Starting local experiment with solution-id - 05 and run-id yellow_market_p9g416119z \n",
      "2023-10-16 16:06:28,769 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:06:28,769 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:06:28,770 name=ffmodel.core.orchestrator level=METRICS solution_config \n",
      "2023-10-16 16:06:28,770 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.static_context_from_file to the pipeline. \n",
      "2023-10-16 16:06:28,775 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.few_shots_from_file to the pipeline. \n",
      "2023-10-16 16:06:28,776 name=ffmodel.core.orchestrator level=INFO Adding component components.stitchers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:06:28,776 name=ffmodel.core.orchestrator level=INFO Adding component components.model_callers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:06:28,777 name=ffmodel.core.orchestrator level=INFO Adding component components.post_processors.minify_json to the pipeline. \n",
      "2023-10-16 16:06:28,777 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.json_schema to the pipeline. \n",
      "2023-10-16 16:06:28,777 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.fuzzy to the pipeline. \n",
      "2023-10-16 16:06:28,778 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.bleu to the pipeline. \n",
      "2023-10-16 16:06:28,778 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.rouge to the pipeline. \n",
      "2023-10-16 16:06:28,778 name=ffmodel.core.orchestrator level=INFO Beginning execution... \n",
      "2023-10-16 16:06:28,778 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.static_context_from_file' \n",
      "2023-10-16 16:06:28,779 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.few_shots_from_file' \n",
      "2023-10-16 16:06:28,779 name=ffmodel.core.orchestrator level=INFO Executing 'components.stitchers.openai_chat_completions' \n",
      "2023-10-16 16:06:28,780 name=ffmodel.core.orchestrator level=INFO Executing 'components.model_callers.openai_chat_completions' \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local environment configs from file.\n",
      "Loaded 2 configs from file '/Users/jorgeluna/.ffmodel.env'.\n",
      "Key vault url not set. Skipping key vault client initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:06:36,397 name=ffmodel.core.orchestrator level=INFO Executing 'components.post_processors.minify_json' \n",
      "2023-10-16 16:06:36,398 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.json_schema' \n",
      "2023-10-16 16:06:36,414 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.fuzzy' \n",
      "2023-10-16 16:06:36,416 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.bleu' \n",
      "2023-10-16 16:06:49,956 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.rouge' \n",
      "2023-10-16 16:06:49,957 name=ffmodel.core.orchestrator level=INFO Finished execution\n",
      "Returning data models \n",
      "2023-10-16 16:06:50,144 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:50,153 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:50,191 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:50,191 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:50,196 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:50,215 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:50,215 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:50,227 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:50,273 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:50,273 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:50,278 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:50,298 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:50,298 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:50,310 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:50,355 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:50,356 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:06:50,362 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:06:50,386 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:06:50,386 name=ffmodel.core.orchestrator level=INFO Finished local experiment \n",
      "2023-10-16 16:06:50,398 name=ffmodel.core.orchestrator level=INFO Starting local experiment with solution-id - 01 and run-id mighty_atemoya_0nt5hnh32j \n",
      "2023-10-16 16:06:50,399 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:06:50,399 name=ffmodel.utils.file_logger level=INFO File Logging is disabled: SolutionConfig and DataModel will not be logged \n",
      "2023-10-16 16:06:50,400 name=ffmodel.core.orchestrator level=METRICS solution_config \n",
      "2023-10-16 16:06:50,400 name=ffmodel.core.orchestrator level=INFO Adding component components.pre_processors.static_context_from_file to the pipeline. \n",
      "2023-10-16 16:06:50,401 name=ffmodel.core.orchestrator level=INFO Adding component components.stitchers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:06:50,401 name=ffmodel.core.orchestrator level=INFO Adding component components.model_callers.openai_chat_completions to the pipeline. \n",
      "2023-10-16 16:06:50,402 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.json_schema to the pipeline. \n",
      "2023-10-16 16:06:50,402 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.fuzzy to the pipeline. \n",
      "2023-10-16 16:06:50,403 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.bleu to the pipeline. \n",
      "2023-10-16 16:06:50,403 name=ffmodel.core.orchestrator level=INFO Adding component components.evaluators.rouge to the pipeline. \n",
      "2023-10-16 16:06:50,403 name=ffmodel.core.orchestrator level=INFO Beginning execution... \n",
      "2023-10-16 16:06:50,403 name=ffmodel.core.orchestrator level=INFO Executing 'components.pre_processors.static_context_from_file' \n",
      "2023-10-16 16:06:50,403 name=ffmodel.core.orchestrator level=INFO Executing 'components.stitchers.openai_chat_completions' \n",
      "2023-10-16 16:06:50,404 name=ffmodel.core.orchestrator level=INFO Executing 'components.model_callers.openai_chat_completions' \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local environment configs from file.\n",
      "Loaded 2 configs from file '/Users/jorgeluna/.ffmodel.env'.\n",
      "Key vault url not set. Skipping key vault client initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:06:57,688 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.json_schema' \n",
      "2023-10-16 16:06:57,698 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.fuzzy' \n",
      "2023-10-16 16:06:57,700 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.bleu' \n",
      "2023-10-16 16:07:13,581 name=ffmodel.core.orchestrator level=INFO Executing 'components.evaluators.rouge' \n",
      "2023-10-16 16:07:13,581 name=ffmodel.core.orchestrator level=INFO Finished execution\n",
      "Returning data models \n",
      "2023-10-16 16:07:13,811 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:07:13,823 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:07:13,868 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:07:13,869 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:07:13,875 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:07:13,900 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:07:13,900 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:07:13,916 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:07:13,978 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:07:13,978 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:07:13,985 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:07:14,009 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:07:14,010 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:07:14,026 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:07:14,086 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:07:14,086 name=ffmodel.core.orchestrator level=METRICS request_complete \n",
      "2023-10-16 16:07:14,090 name=ffmodel.core.orchestrator level=METRICS evaluation_metrics \n",
      "2023-10-16 16:07:14,105 name=ffmodel.core.orchestrator level=METRICS final_data_model \n",
      "2023-10-16 16:07:14,106 name=ffmodel.core.orchestrator level=INFO Finished local experiment \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import os\n",
    "\n",
    "def list_full_paths(directory):\n",
    "    return [os.path.join(directory, file) for file in os.listdir(directory)]\n",
    "\n",
    "for solution_config_path in list_full_paths(r'../solution/configs'):\n",
    "    print(\"RUNNING EXPERIMENT FOR CONFIG: \" + str(solution_config_path))\n",
    "    orchestrator.execute_experiment_on_local(solution_config_path, environment_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"component_data\": {},\n",
      "    \"context\": [\n",
      "        \"*You are bot that takes orders at a pizza and wings restaurant\\n*You take orders in natural language and translate it to a formatted json object\\n*Results should be provided in a structured output that is json format that adheres to this schema\\n    {\\\"$schema\\\":\\\"http://json-schema.org/draft-07/schema#\\\",\\\"type\\\":\\\"array\\\",\\\"description\\\":\\\"An array of items in the order\\\",\\\"items\\\":{\\\"type\\\":\\\"object\\\",\\\"oneOf\\\":[{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"specialty pizza\\\"},\\\"name\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of the pizza\\\"},\\\"size\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The size of the pizza\\\"},\\\"crust\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The type of crust for the pizza\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the pizza in the order\\\"}},\\\"required\\\":[\\\"type\\\",\\\"name\\\",\\\"quantity\\\",\\\"size\\\",\\\"crust\\\"]},{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"custom pizza\\\"},\\\"size\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The size of the pizza\\\"},\\\"crust\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The type of crust for the pizza\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the pizza in the order\\\"},\\\"toppings\\\":{\\\"type\\\":\\\"array\\\",\\\"description\\\":\\\"An array of toppings on the pizza\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of a topping\\\"}}},\\\"required\\\":[\\\"type\\\",\\\"size\\\",\\\"crust\\\",\\\"quantity\\\",\\\"toppings\\\"]},{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"wings\\\"},\\\"name\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of the wings\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the wings in the order\\\"},\\\"flavor\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The flavor of the wings\\\"}},\\\"required\\\":[\\\"type\\\",\\\"name\\\",\\\"quantity\\\",\\\"flavor\\\"]},{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"drink\\\"},\\\"name\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of the drink\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the drink in the order\\\"},\\\"size\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The size of the drink\\\"}},\\\"required\\\":[\\\"type\\\",\\\"name\\\",\\\"quantity\\\",\\\"size\\\"]},{\\\"properties\\\":{\\\"type\\\":{\\\"const\\\":\\\"topping\\\"},\\\"name\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"The name of the topping\\\"},\\\"quantity\\\":{\\\"type\\\":\\\"integer\\\",\\\"description\\\":\\\"The quantity of the topping in the order\\\"}},\\\"required\\\":[\\\"type\\\",\\\"name\\\",\\\"quantity\\\"]}]}}\\n*If asked to order anything that is not related to pizza, wings, or drinks, you politely decline.\\n\"\n",
      "    ],\n",
      "    \"completion_pairs\": [],\n",
      "    \"session\": [],\n",
      "    \"user_nl\": \"Two large pepperoni and mushroom pizzas with thick crust and 1 medium thin crust veggie deluxe\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(data_models[i].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[\\n  {\\n    \"type\": \"specialty pizza\",\\n    \"name\": \"pepperoni and mushroom\",\\n    \"size\": \"large\",\\n    \"crust\": \"thick\",\\n    \"quantity\": 2\\n  },\\n  {\\n    \"type\": \"specialty pizza\",\\n    \"name\": \"veggie deluxe\",\\n    \"size\": \"medium\",\\n    \"crust\": \"thin\",\\n    \"quantity\": 1\\n  }\\n]']\n"
     ]
    }
   ],
   "source": [
    "print(data_models[i].model_output.completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'items': [{'type': 'specialty pizza', 'name': 'Veggie Deluxe', 'size': 'medium', 'crust': 'thin', 'quantity': 1}, {'type': 'custom pizza', 'size': 'large', 'crust': 'pan', 'quantity': 2, 'toppings': ['pepperoni', 'mushrooms']}]}]\n"
     ]
    }
   ],
   "source": [
    "print(data_models[i].request.expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'components.model_callers.openai_chat_completions': {'prompt_tokens': [521],\n",
       "  'completion_tokens': [94],\n",
       "  'total_tokens': [615]},\n",
       " 'components.evaluators.json_schema': {'valid_syntax': [1],\n",
       "  'valid_object': [0]},\n",
       " 'components.evaluators.fuzzy': {'simple': [0.48], 'partial': [0.47]},\n",
       " 'components.evaluators.bleu': {'bleu_score_ngrams_1': [1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   ...]},\n",
       " 'components.evaluators.rouge': {'rouge1_precision': [0.8],\n",
       "  'rouge1_recall': [0.8],\n",
       "  'rouge1_fmeasure': [0.8000000000000002]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_models[i].experiment_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
